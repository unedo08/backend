{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load('dataset/x_train_np.npy')\n",
    "x_cv=np.load('dataset/x_cv_np.npy')\n",
    "y_train=np.load('dataset/y_train_np.npy')\n",
    "y_cv=np.load('dataset/y_cv_np.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.load('dataset/x_test_np.npy', allow_pickle=True)\n",
    "y_test=np.load('dataset/y_test_np.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_lr(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        K.set_value(self.model.optimizer.lr, 0.001)\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        lr_present=K.get_value(self.model.optimizer.lr)\n",
    "        #print(epoch)\n",
    "        if (epoch%10==0) and epoch:\n",
    "            K.set_value(self.model.optimizer.lr, lr_present/((epoch)**0.5))\n",
    "            print(K.get_value(self.model.optimizer.lr))\n",
    "            print(lr_present/((epoch)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "x_train_bottleneck = model.predict(x_train)\n",
    "x_cv_bottleneck = model.predict(x_cv)\n",
    "\n",
    "np.save('dataset/x_train_bottleneck.npy', x_train_bottleneck)\n",
    "np.save('dataset/x_cv_bottleneck.npy', x_cv_bottleneck)\n",
    "\n",
    "print(x_train_bottleneck[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 0.       , ..., 0.       , 1.2254674,\n",
       "         0.       ]],\n",
       "\n",
       "       [[0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_bottleneck[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bottleneck = np.load('dataset/x_train_bottleneck.npy')\n",
    "x_cv_bottleneck = np.load('dataset/x_cv_bottleneck.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_bottleneck.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=x_train_bottleneck.shape[1:]))\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "top_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 131,201\n",
      "Trainable params: 131,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    Custom_lr()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 1.4072 - accuracy: 0.5875 - val_loss: 0.6332 - val_accuracy: 0.6786\n",
      "Epoch 2/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.6074 - accuracy: 0.6659 - val_loss: 0.6189 - val_accuracy: 0.6882\n",
      "Epoch 3/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.6938 - val_loss: 0.6074 - val_accuracy: 0.6967\n",
      "Epoch 4/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7159 - val_loss: 0.6281 - val_accuracy: 0.6967\n",
      "Epoch 5/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7310 - val_loss: 0.6097 - val_accuracy: 0.7012\n",
      "Epoch 6/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7443 - val_loss: 0.6149 - val_accuracy: 0.7053\n",
      "Epoch 7/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7419 - val_loss: 0.6241 - val_accuracy: 0.7094\n",
      "Epoch 8/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7603 - val_loss: 0.6320 - val_accuracy: 0.7105\n",
      "Epoch 9/35\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7600 - val_loss: 0.6061 - val_accuracy: 0.7163\n",
      "Epoch 10/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.7765 - val_loss: 0.6617 - val_accuracy: 0.7019\n",
      "0.0003162278\n",
      "0.00031622778103685084\n",
      "Epoch 11/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.3790 - accuracy: 0.7897 - val_loss: 0.6537 - val_accuracy: 0.7153\n",
      "Epoch 12/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8026 - val_loss: 0.6651 - val_accuracy: 0.7197\n",
      "Epoch 13/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8094 - val_loss: 0.6775 - val_accuracy: 0.7266\n",
      "Epoch 14/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8241 - val_loss: 0.6975 - val_accuracy: 0.7228\n",
      "Epoch 15/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8241 - val_loss: 0.7105 - val_accuracy: 0.7276\n",
      "Epoch 16/35\n",
      "213/213 [==============================] - 1s 2ms/step - loss: 0.3073 - accuracy: 0.8329 - val_loss: 0.7513 - val_accuracy: 0.7214\n",
      "Epoch 17/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.8294 - val_loss: 0.7623 - val_accuracy: 0.7218\n",
      "Epoch 18/35\n",
      "213/213 [==============================] - 0s 948us/step - loss: 0.3026 - accuracy: 0.8332 - val_loss: 0.7592 - val_accuracy: 0.7208\n",
      "Epoch 19/35\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.8375 - val_loss: 0.7830 - val_accuracy: 0.7249\n",
      "Epoch 20/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8384 - val_loss: 0.7880 - val_accuracy: 0.7221\n",
      "7.071068e-05\n",
      "7.071068264135355e-05\n",
      "Epoch 21/35\n",
      "213/213 [==============================] - 0s 962us/step - loss: 0.2763 - accuracy: 0.8459 - val_loss: 0.8106 - val_accuracy: 0.7221\n",
      "Epoch 22/35\n",
      "213/213 [==============================] - 0s 962us/step - loss: 0.2654 - accuracy: 0.8528 - val_loss: 0.8206 - val_accuracy: 0.7214\n",
      "Epoch 23/35\n",
      "213/213 [==============================] - 0s 939us/step - loss: 0.2662 - accuracy: 0.8541 - val_loss: 0.8319 - val_accuracy: 0.7221\n",
      "Epoch 24/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.2579 - accuracy: 0.8575 - val_loss: 0.8458 - val_accuracy: 0.7249\n",
      "Epoch 25/35\n",
      "213/213 [==============================] - 0s 981us/step - loss: 0.2592 - accuracy: 0.8547 - val_loss: 0.8524 - val_accuracy: 0.7245\n",
      "Epoch 26/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.2629 - accuracy: 0.8551 - val_loss: 0.8561 - val_accuracy: 0.7238\n",
      "Epoch 27/35\n",
      "213/213 [==============================] - 0s 944us/step - loss: 0.2583 - accuracy: 0.8588 - val_loss: 0.8628 - val_accuracy: 0.7273\n",
      "Epoch 28/35\n",
      "213/213 [==============================] - 0s 944us/step - loss: 0.2528 - accuracy: 0.8584 - val_loss: 0.8702 - val_accuracy: 0.7293\n",
      "Epoch 29/35\n",
      "213/213 [==============================] - 0s 986us/step - loss: 0.2489 - accuracy: 0.8637 - val_loss: 0.8828 - val_accuracy: 0.7280\n",
      "Epoch 30/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.8688 - val_loss: 0.9004 - val_accuracy: 0.7307\n",
      "1.2909945e-05\n",
      "1.2909945018820682e-05\n",
      "Epoch 31/35\n",
      "213/213 [==============================] - 0s 986us/step - loss: 0.2433 - accuracy: 0.8638 - val_loss: 0.9009 - val_accuracy: 0.7300\n",
      "Epoch 32/35\n",
      "213/213 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.8607 - val_loss: 0.9040 - val_accuracy: 0.7307\n",
      "Epoch 33/35\n",
      "213/213 [==============================] - 0s 934us/step - loss: 0.2439 - accuracy: 0.8626 - val_loss: 0.9078 - val_accuracy: 0.7317\n",
      "Epoch 34/35\n",
      "213/213 [==============================] - 0s 977us/step - loss: 0.2431 - accuracy: 0.8631 - val_loss: 0.9116 - val_accuracy: 0.7304\n",
      "Epoch 35/35\n",
      "213/213 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.8650 - val_loss: 0.9144 - val_accuracy: 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a883112ac0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.fit(x_train_bottleneck, y_train,\n",
    "          epochs=35,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_cv_bottleneck, y_cv), callbacks=callbacks,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.save('top_model_full_data_custom_lr_weights.h5') # best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load VGG16\n",
    "vgg_model=applications.VGG16(weights='imagenet', include_top=False, input_shape=(64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug=Sequential()\n",
    "model_aug.add(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=(2, 2, 512)))\n",
    "top_model.add(Dense(64, activation='relu'))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "# top_model.load_weights('top_model_full_data_custom_lr_weights.h5')\n",
    "model_aug.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_aug.layers[0].layers[:17]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 131201    \n",
      "=================================================================\n",
      "Total params: 14,845,889\n",
      "Trainable params: 2,491,009\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_aug.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 93,  69,  48],\n",
       "         [ 97,  71,  63],\n",
       "         [102,  80,  65],\n",
       "         ...,\n",
       "         [ 94,  66,  45],\n",
       "         [ 90,  68,  52],\n",
       "         [ 90,  72,  53]],\n",
       "\n",
       "        [[ 91,  70,  50],\n",
       "         [ 98,  77,  61],\n",
       "         [ 98,  75,  57],\n",
       "         ...,\n",
       "         [100,  75,  48],\n",
       "         [ 96,  74,  53],\n",
       "         [ 94,  69,  56]],\n",
       "\n",
       "        [[ 95,  75,  58],\n",
       "         [100,  84,  63],\n",
       "         [ 96,  69,  50],\n",
       "         ...,\n",
       "         [102,  81,  52],\n",
       "         [101,  75,  55],\n",
       "         [ 98,  72,  58]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 87,  66,  46],\n",
       "         [ 91,  70,  52],\n",
       "         [ 96,  73,  51],\n",
       "         ...,\n",
       "         [ 98,  74,  56],\n",
       "         [ 99,  71,  48],\n",
       "         [ 93,  66,  46]],\n",
       "\n",
       "        [[ 87,  66,  45],\n",
       "         [ 92,  73,  54],\n",
       "         [ 93,  71,  52],\n",
       "         ...,\n",
       "         [105,  80,  68],\n",
       "         [109,  80,  65],\n",
       "         [105,  78,  59]],\n",
       "\n",
       "        [[ 86,  62,  39],\n",
       "         [ 98,  76,  60],\n",
       "         [ 94,  74,  58],\n",
       "         ...,\n",
       "         [107,  81,  66],\n",
       "         [108,  78,  60],\n",
       "         [104,  77,  55]]],\n",
       "\n",
       "\n",
       "       [[[212, 212, 210],\n",
       "         [214, 214, 212],\n",
       "         [211, 211, 209],\n",
       "         ...,\n",
       "         [141, 141, 139],\n",
       "         [141, 141, 139],\n",
       "         [146, 146, 144]],\n",
       "\n",
       "        [[199, 199, 197],\n",
       "         [212, 212, 210],\n",
       "         [204, 204, 202],\n",
       "         ...,\n",
       "         [146, 146, 144],\n",
       "         [145, 145, 143],\n",
       "         [148, 148, 146]],\n",
       "\n",
       "        [[204, 204, 202],\n",
       "         [205, 205, 203],\n",
       "         [200, 200, 199],\n",
       "         ...,\n",
       "         [140, 140, 138],\n",
       "         [146, 146, 144],\n",
       "         [145, 145, 143]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[209, 209, 207],\n",
       "         [201, 201, 199],\n",
       "         [201, 201, 199],\n",
       "         ...,\n",
       "         [145, 145, 143],\n",
       "         [131, 131, 129],\n",
       "         [136, 136, 134]],\n",
       "\n",
       "        [[203, 203, 201],\n",
       "         [202, 202, 200],\n",
       "         [204, 204, 202],\n",
       "         ...,\n",
       "         [142, 142, 140],\n",
       "         [150, 150, 148],\n",
       "         [146, 146, 144]],\n",
       "\n",
       "        [[200, 200, 198],\n",
       "         [203, 203, 201],\n",
       "         [212, 212, 210],\n",
       "         ...,\n",
       "         [141, 141, 139],\n",
       "         [140, 140, 138],\n",
       "         [131, 131, 129]]],\n",
       "\n",
       "\n",
       "       [[[124,  64,   0],\n",
       "         [124,  66,   0],\n",
       "         [125,  66,   0],\n",
       "         ...,\n",
       "         [116,  63,   1],\n",
       "         [113,  60,   0],\n",
       "         [114,  61,   0]],\n",
       "\n",
       "        [[126,  68,   0],\n",
       "         [123,  67,   0],\n",
       "         [125,  64,   0],\n",
       "         ...,\n",
       "         [115,  64,   0],\n",
       "         [114,  62,   1],\n",
       "         [117,  64,   2]],\n",
       "\n",
       "        [[122,  66,   0],\n",
       "         [122,  67,   0],\n",
       "         [123,  66,   0],\n",
       "         ...,\n",
       "         [112,  63,   0],\n",
       "         [114,  65,   1],\n",
       "         [115,  64,   2]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[182, 121,  28],\n",
       "         [185, 122,  35],\n",
       "         [185, 123,  39],\n",
       "         ...,\n",
       "         [142,  84,   3],\n",
       "         [144,  86,   7],\n",
       "         [145,  88,   9]],\n",
       "\n",
       "        [[184, 122,  32],\n",
       "         [185, 123,  35],\n",
       "         [187, 124,  36],\n",
       "         ...,\n",
       "         [145,  86,   5],\n",
       "         [145,  87,   8],\n",
       "         [143,  86,   7]],\n",
       "\n",
       "        [[185, 125,  37],\n",
       "         [182, 122,  25],\n",
       "         [186, 124,  29],\n",
       "         ...,\n",
       "         [144,  85,   5],\n",
       "         [144,  85,   6],\n",
       "         [144,  86,   2]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[126, 119, 100],\n",
       "         [123, 109,  91],\n",
       "         [129, 117, 101],\n",
       "         ...,\n",
       "         [126, 117, 101],\n",
       "         [124, 116, 103],\n",
       "         [117, 109,  96]],\n",
       "\n",
       "        [[125, 114, 101],\n",
       "         [122, 109,  95],\n",
       "         [113, 105,  89],\n",
       "         ...,\n",
       "         [121, 113,  96],\n",
       "         [120, 113,  98],\n",
       "         [123, 117, 100]],\n",
       "\n",
       "        [[128, 117, 105],\n",
       "         [127, 117, 104],\n",
       "         [132, 126, 111],\n",
       "         ...,\n",
       "         [120, 113,  99],\n",
       "         [115, 107,  93],\n",
       "         [117, 109,  96]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[129, 125,  73],\n",
       "         [134, 139,  83],\n",
       "         [102, 109,  64],\n",
       "         ...,\n",
       "         [142, 152,  85],\n",
       "         [120, 125,  69],\n",
       "         [138, 143,  87]],\n",
       "\n",
       "        [[107,  99,  54],\n",
       "         [155, 146,  96],\n",
       "         [191, 192, 142],\n",
       "         ...,\n",
       "         [121, 129,  64],\n",
       "         [158, 171, 105],\n",
       "         [103, 111,  57]],\n",
       "\n",
       "        [[185, 185, 140],\n",
       "         [142, 135,  91],\n",
       "         [161, 155, 101],\n",
       "         ...,\n",
       "         [120, 124,  67],\n",
       "         [154, 160,  96],\n",
       "         [136, 145,  90]]],\n",
       "\n",
       "\n",
       "       [[[ 16,  29,  14],\n",
       "         [ 17,  28,  14],\n",
       "         [ 15,  24,  12],\n",
       "         ...,\n",
       "         [ 46,  56,  36],\n",
       "         [ 69,  75,  52],\n",
       "         [126, 147,  92]],\n",
       "\n",
       "        [[ 14,  26,  10],\n",
       "         [ 15,  24,  11],\n",
       "         [ 12,  18,   8],\n",
       "         ...,\n",
       "         [ 51,  64,  38],\n",
       "         [ 50,  54,  29],\n",
       "         [ 56,  69,  28]],\n",
       "\n",
       "        [[ 15,  18,   6],\n",
       "         [ 14,  20,   9],\n",
       "         [ 11,  23,  11],\n",
       "         ...,\n",
       "         [ 62,  76,  44],\n",
       "         [ 59,  66,  35],\n",
       "         [ 45,  59,  22]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[115, 120, 104],\n",
       "         [118, 124, 106],\n",
       "         [115, 123, 102],\n",
       "         ...,\n",
       "         [ 66,  70,  59],\n",
       "         [ 69,  66,  57],\n",
       "         [ 76,  69,  60]],\n",
       "\n",
       "        [[115, 122, 104],\n",
       "         [116, 125, 103],\n",
       "         [115, 124, 101],\n",
       "         ...,\n",
       "         [ 63,  70,  56],\n",
       "         [ 72,  69,  59],\n",
       "         [ 75,  68,  59]],\n",
       "\n",
       "        [[116, 121, 101],\n",
       "         [116, 123, 102],\n",
       "         [115, 123, 102],\n",
       "         ...,\n",
       "         [ 67,  70,  56],\n",
       "         [ 73,  69,  58],\n",
       "         [ 74,  69,  58]]],\n",
       "\n",
       "\n",
       "       [[[ 26,  31,  24],\n",
       "         [ 17,  20,  15],\n",
       "         [  9,   9,   7],\n",
       "         ...,\n",
       "         [ 51,  50,  41],\n",
       "         [ 56,  51,  46],\n",
       "         [ 65,  62,  58]],\n",
       "\n",
       "        [[ 19,  21,  17],\n",
       "         [ 23,  26,  21],\n",
       "         [ 37,  40,  35],\n",
       "         ...,\n",
       "         [ 39,  36,  33],\n",
       "         [ 53,  51,  45],\n",
       "         [ 35,  31,  33]],\n",
       "\n",
       "        [[ 21,  26,  19],\n",
       "         [ 31,  38,  29],\n",
       "         [ 35,  40,  32],\n",
       "         ...,\n",
       "         [ 39,  36,  31],\n",
       "         [ 44,  41,  37],\n",
       "         [ 52,  48,  43]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[135, 124, 106],\n",
       "         [136, 125, 107],\n",
       "         [134, 128, 109],\n",
       "         ...,\n",
       "         [ 23,  26,  23],\n",
       "         [ 18,  23,  19],\n",
       "         [ 18,  23,  20]],\n",
       "\n",
       "        [[136, 126, 106],\n",
       "         [138, 130, 108],\n",
       "         [134, 130, 108],\n",
       "         ...,\n",
       "         [ 26,  28,  25],\n",
       "         [ 20,  23,  20],\n",
       "         [ 18,  23,  19]],\n",
       "\n",
       "        [[134, 127, 108],\n",
       "         [134, 130, 107],\n",
       "         [137, 131, 108],\n",
       "         ...,\n",
       "         [ 25,  27,  23],\n",
       "         [ 21,  23,  20],\n",
       "         [ 17,  20,  18]]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "213/213 [==============================] - 53s 247ms/step - loss: 3.6210 - accuracy: 0.5378 - val_loss: 3.1442 - val_accuracy: 0.5444\n",
      "Epoch 2/35\n",
      "213/213 [==============================] - 58s 272ms/step - loss: 3.0079 - accuracy: 0.5531 - val_loss: 2.8566 - val_accuracy: 0.5571\n",
      "Epoch 3/35\n",
      "213/213 [==============================] - 61s 288ms/step - loss: 2.6673 - accuracy: 0.5671 - val_loss: 2.6748 - val_accuracy: 0.5691\n",
      "Epoch 4/35\n",
      "213/213 [==============================] - 57s 267ms/step - loss: 2.4039 - accuracy: 0.5844 - val_loss: 2.5340 - val_accuracy: 0.5760\n",
      "Epoch 5/35\n",
      "213/213 [==============================] - 58s 274ms/step - loss: 2.1880 - accuracy: 0.6009 - val_loss: 2.4211 - val_accuracy: 0.5825\n",
      "Epoch 6/35\n",
      "213/213 [==============================] - 62s 289ms/step - loss: 2.0053 - accuracy: 0.6140 - val_loss: 2.3265 - val_accuracy: 0.5846\n",
      "Epoch 7/35\n",
      "213/213 [==============================] - 60s 283ms/step - loss: 1.8470 - accuracy: 0.6274 - val_loss: 2.2493 - val_accuracy: 0.5883\n",
      "Epoch 8/35\n",
      "213/213 [==============================] - 65s 307ms/step - loss: 1.7082 - accuracy: 0.6388 - val_loss: 2.1826 - val_accuracy: 0.5921\n",
      "Epoch 9/35\n",
      "213/213 [==============================] - 60s 283ms/step - loss: 1.5837 - accuracy: 0.6516 - val_loss: 2.1255 - val_accuracy: 0.5955\n",
      "Epoch 10/35\n",
      "213/213 [==============================] - 60s 282ms/step - loss: 1.4718 - accuracy: 0.6624 - val_loss: 2.0749 - val_accuracy: 0.5976\n",
      "Epoch 11/35\n",
      "213/213 [==============================] - 58s 274ms/step - loss: 1.3714 - accuracy: 0.6710 - val_loss: 2.0285 - val_accuracy: 0.6014\n",
      "Epoch 12/35\n",
      "213/213 [==============================] - 59s 275ms/step - loss: 1.2791 - accuracy: 0.6828 - val_loss: 1.9914 - val_accuracy: 0.6021\n",
      "Epoch 13/35\n",
      "213/213 [==============================] - 58s 273ms/step - loss: 1.1966 - accuracy: 0.6940 - val_loss: 1.9550 - val_accuracy: 0.6038\n",
      "Epoch 14/35\n",
      "213/213 [==============================] - 59s 276ms/step - loss: 1.1217 - accuracy: 0.7031 - val_loss: 1.9216 - val_accuracy: 0.6075\n",
      "Epoch 15/35\n",
      "213/213 [==============================] - 60s 281ms/step - loss: 1.0522 - accuracy: 0.7135 - val_loss: 1.8939 - val_accuracy: 0.6110\n",
      "Epoch 16/35\n",
      "213/213 [==============================] - 60s 281ms/step - loss: 0.9877 - accuracy: 0.7221 - val_loss: 1.8666 - val_accuracy: 0.6127\n",
      "Epoch 17/35\n",
      "213/213 [==============================] - 59s 277ms/step - loss: 0.9279 - accuracy: 0.7321 - val_loss: 1.8428 - val_accuracy: 0.6123\n",
      "Epoch 18/35\n",
      "213/213 [==============================] - 61s 284ms/step - loss: 0.8726 - accuracy: 0.7396 - val_loss: 1.8188 - val_accuracy: 0.6151\n",
      "Epoch 19/35\n",
      "213/213 [==============================] - 61s 285ms/step - loss: 0.8214 - accuracy: 0.7503 - val_loss: 1.7996 - val_accuracy: 0.6165\n",
      "Epoch 20/35\n",
      "213/213 [==============================] - 61s 286ms/step - loss: 0.7740 - accuracy: 0.7571 - val_loss: 1.7828 - val_accuracy: 0.6158\n",
      "Epoch 21/35\n",
      "213/213 [==============================] - 59s 279ms/step - loss: 0.7301 - accuracy: 0.7662 - val_loss: 1.7659 - val_accuracy: 0.6192\n",
      "Epoch 22/35\n",
      "213/213 [==============================] - 58s 270ms/step - loss: 0.6900 - accuracy: 0.7753 - val_loss: 1.7484 - val_accuracy: 0.6182\n",
      "Epoch 23/35\n",
      "213/213 [==============================] - 60s 283ms/step - loss: 0.6528 - accuracy: 0.7835 - val_loss: 1.7354 - val_accuracy: 0.6196\n",
      "Epoch 24/35\n",
      "213/213 [==============================] - 62s 292ms/step - loss: 0.6183 - accuracy: 0.7907 - val_loss: 1.7220 - val_accuracy: 0.6220\n",
      "Epoch 25/35\n",
      "213/213 [==============================] - 58s 272ms/step - loss: 0.5860 - accuracy: 0.7994 - val_loss: 1.7078 - val_accuracy: 0.6220\n",
      "Epoch 26/35\n",
      "213/213 [==============================] - 59s 275ms/step - loss: 0.5561 - accuracy: 0.8072 - val_loss: 1.6947 - val_accuracy: 0.6240\n",
      "Epoch 27/35\n",
      "213/213 [==============================] - 59s 275ms/step - loss: 0.5274 - accuracy: 0.8160 - val_loss: 1.6848 - val_accuracy: 0.6250\n",
      "Epoch 28/35\n",
      "213/213 [==============================] - 59s 277ms/step - loss: 0.5008 - accuracy: 0.8235 - val_loss: 1.6727 - val_accuracy: 0.6274\n",
      "Epoch 29/35\n",
      "213/213 [==============================] - 59s 276ms/step - loss: 0.4759 - accuracy: 0.8276 - val_loss: 1.6645 - val_accuracy: 0.6305\n",
      "Epoch 30/35\n",
      "213/213 [==============================] - 62s 293ms/step - loss: 0.4525 - accuracy: 0.8343 - val_loss: 1.6537 - val_accuracy: 0.6357\n",
      "Epoch 31/35\n",
      "213/213 [==============================] - 59s 278ms/step - loss: 0.4306 - accuracy: 0.8404 - val_loss: 1.6446 - val_accuracy: 0.6367\n",
      "Epoch 32/35\n",
      "213/213 [==============================] - 59s 277ms/step - loss: 0.4096 - accuracy: 0.8456 - val_loss: 1.6379 - val_accuracy: 0.6374\n",
      "Epoch 33/35\n",
      "213/213 [==============================] - 58s 274ms/step - loss: 0.3900 - accuracy: 0.8529 - val_loss: 1.6287 - val_accuracy: 0.6381\n",
      "Epoch 34/35\n",
      "213/213 [==============================] - 60s 283ms/step - loss: 0.3718 - accuracy: 0.8593 - val_loss: 1.6224 - val_accuracy: 0.6388\n",
      "Epoch 35/35\n",
      "213/213 [==============================] - 59s 278ms/step - loss: 0.3545 - accuracy: 0.8651 - val_loss: 1.6155 - val_accuracy: 0.6405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2901fc78610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aug.fit(x_train, y_train, epochs=35, batch_size=32, validation_data=(x_cv, y_cv), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5264753 ],\n",
       "       [0.94470495],\n",
       "       [0.66361344],\n",
       "       [0.00169832],\n",
       "       [0.02029553],\n",
       "       [0.00563926],\n",
       "       [0.942483  ],\n",
       "       [0.9331857 ],\n",
       "       [0.00266075],\n",
       "       [0.5745946 ],\n",
       "       [0.02291301],\n",
       "       [0.9829025 ],\n",
       "       [0.08444613],\n",
       "       [0.9674344 ],\n",
       "       [0.5789391 ],\n",
       "       [0.9999796 ],\n",
       "       [0.04543281],\n",
       "       [0.9433596 ],\n",
       "       [0.99575675],\n",
       "       [0.07195842]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aug.predict(x_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_aug.predict(x_train[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5264753 ],\n",
       "       [0.9447048 ],\n",
       "       [0.66361344],\n",
       "       [0.00169832]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 34s 159ms/step - loss: 0.3364 - accuracy: 0.8696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3364208936691284, 0.8695588111877441]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_aug.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_aug.predict(x_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake images\n",
    "allFakeResults=[]\n",
    "for i in range(10):\n",
    "    result = model_aug.predict(x_test[i])\n",
    "    allFakeResults.append(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([0.99983954], dtype=float32),\n",
       " array([0.99999666], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFakeResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pristine images\n",
    "allPristineResults=[]\n",
    "for i in range(10, 20):\n",
    "    result = model_aug.predict(x_test[i])\n",
    "    allPristineResults.append(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.9999485], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPristineResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 64, 64, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pristine images dari train data deh :\"D\n",
    "allPristineResults=[]\n",
    "for i in range(0,100,10):\n",
    "    result = model_aug.predict(x_train[i:i+10])\n",
    "    allPristineResults.append(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.9959935], dtype=float32),\n",
       " array([0.99995804], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([0.9818442], dtype=float32),\n",
       " array([0.99775153], dtype=float32),\n",
       " array([0.9900132], dtype=float32),\n",
       " array([0.9999999], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([0.9767355], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPristineResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake images\n",
    "allFakeResults=[]\n",
    "for i in range(5000,5100,10):\n",
    "    result = model_aug.predict(x_train[i:i+10])\n",
    "    allFakeResults.append(max(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.9999933], dtype=float32),\n",
       " array([0.99972486], dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([0.999983], dtype=float32),\n",
       " array([0.9696905], dtype=float32),\n",
       " array([0.9976498], dtype=float32),\n",
       " array([0.99992055], dtype=float32),\n",
       " array([0.99961364], dtype=float32),\n",
       " array([0.9918443], dtype=float32),\n",
       " array([0.99995595], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFakeResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug.save('fine_tuned_model_adam_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
